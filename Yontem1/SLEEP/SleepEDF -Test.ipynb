{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee813201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy import stats\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd57375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks, welch\n",
    "from scipy.stats import entropy, kurtosis, skew, iqr\n",
    "\n",
    "def extract_features_multi(data, sfreq):\n",
    "    feature_list = []\n",
    "    count = 0\n",
    "    \n",
    "    # Zaman serisinde ozellik cikarimi yapiyorum. Buradaki ozniteliklerin cogunu TSFEL: Time Series Feature Extraction Library makalesinden aldim.\n",
    "\n",
    "    for epoch in data:\n",
    "        feats = []\n",
    "        for ch_signal in epoch:\n",
    "            t = np.arange(len(ch_signal))\n",
    "            abs_energy = np.sum(ch_signal**2)                                                           # Sinyalin toplam enerjisi, guc olcusu\n",
    "            area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n",
    "            \n",
    "            autocorr = np.corrcoef(ch_signal[:-1], ch_signal[1:])[0, 1] if np.std(ch_signal) > 0 else 0 # Sinyalin kendisiyle bir gecikmeyle olan korelasyonu\n",
    "            \n",
    "            avg_power = np.mean(ch_signal**2)                                                           # Ortalama guc\n",
    "            centroid = np.sum(t * np.abs(ch_signal)) / (np.sum(np.abs(ch_signal)) + 1e-12)              # Sinyal agirlik merkezi\n",
    "            \n",
    "            hist, _ = np.histogram(ch_signal, bins=10, density=True)\n",
    "            hist_entropy = entropy(hist + 1e-12)                                                        # Sinyal genlik dagiliminin duzensizligi\n",
    "            \n",
    "            freqs, psd = welch(ch_signal, sfreq, nperseg=min(256, len(ch_signal)))\n",
    "            psd /= np.sum(psd) + 1e-12                                                                  # Frekanslara gore enerji dagilimi\n",
    "            \n",
    "            fund_freq = freqs[np.argmax(psd)] if len(psd) > 0 else 0                                    # En yuksek guce sahip frekans bileşeni\n",
    "            \n",
    "            hist_vals, hist_bins = np.histogram(ch_signal, bins=10)\n",
    "            hist_mode = hist_bins[np.argmax(hist_vals)]                                                 # En cok gorulen genlik degeri\n",
    "            \n",
    "            human_energy = np.sum(psd[(freqs >= 0.5) & (freqs <= 40)])                                  # Insan EEG bandindaki enerji\n",
    "            iqr_val = iqr(ch_signal)                                                                    # Sinyalin orta %50'sinin yayilimi\n",
    "            kurt_val = kurtosis(ch_signal)                                                              # Carpiklik, uc deger yogunlugu\n",
    "            \n",
    "            max_val = np.max(ch_signal)                                                                 # Maksimum deger\n",
    "            max_psd = np.max(psd)                                                                       # Maksimum guc\n",
    "            max_freq = freqs[-1]                                                                         # En yuksek olculebilir frekans\n",
    "            \n",
    "            mean_val = np.mean(ch_signal)                                                               # Ortalama deger\n",
    "            mad = np.mean(np.abs(ch_signal - mean_val))                                                 # Ortalama mutlak sapma\n",
    "            mean_abs_diff = np.mean(np.abs(np.diff(ch_signal)))                                         # Komşu ornekler arasindaki ortalama mutlak fark\n",
    "            mean_diff = np.mean(np.diff(ch_signal))                                                     # Komşu ornekler arasindaki ortalama fark\n",
    "            \n",
    "            med_val = np.median(ch_signal)                                                              # Medyan deger\n",
    "            med_abs_dev = np.median(np.abs(ch_signal - med_val))                                        # Medyan mutlak sapma\n",
    "            med_abs_diff = np.median(np.abs(np.diff(ch_signal)))                                        # Medyan komşu mutlak farki\n",
    "            med_diff = np.median(np.diff(ch_signal))                                                    # Medyan komşu farki\n",
    "            cumulative_power = np.cumsum(psd)\n",
    "            med_freq = freqs[np.argmax(cumulative_power >= 0.5)] if len(psd) > 0 else 0                 # Medyan frekans\n",
    "            \n",
    "            min_val = np.min(ch_signal)                                                                 # Minimum deger\n",
    "            \n",
    "            diff_signal = np.diff(ch_signal)\n",
    "            sign_changes = np.diff(np.sign(diff_signal))\n",
    "            neg_turning = np.sum(sign_changes > 0)                                                      # Negatif egimden pozitif egime geciş sayisi\n",
    "            pos_turning = np.sum(sign_changes < 0)                                                      # Pozitif egimden negatif egime geciş sayisi\n",
    "            peaks, _ = find_peaks(ch_signal)\n",
    "            n_peaks = len(peaks)                                                                        # Tepe sayisi\n",
    "            peak_dist = np.mean(np.diff(peaks)) if n_peaks > 1 else 0                                   # Tepeler arasi ortalama mesafe\n",
    "            \n",
    "            if len(psd) > 0:\n",
    "                peak_psd = np.max(psd)\n",
    "                mask = psd >= (peak_psd / 2)\n",
    "                try:\n",
    "                    power_bandwidth = freqs[mask][-1] - freqs[mask][0]                                  # Gucun %50'sinden fazlasini iceren frekans araligi\n",
    "                except:\n",
    "                    power_bandwidth = 0\n",
    "            else:\n",
    "                power_bandwidth = 0\n",
    "                \n",
    "            rms = np.sqrt(avg_power)                                                                    \n",
    "            signal_dist = np.sum(np.abs(ch_signal))                                                     # Mutlak genlik toplami\n",
    "            skew_val = skew(ch_signal)                                                                  # Simetri olcusu\n",
    "            slope = np.polyfit(t, ch_signal, 1)[0]                                                      # Lineer egim, trend\n",
    "            \n",
    "            spec_centroid = np.sum(freqs * psd) / (np.sum(psd) + 1e-12)                                 # Spektral agirlik merkezi\n",
    "            spec_decrease = np.sum((psd[1:] - psd[0]) / np.arange(1, len(psd))) / (np.sum(psd[1:]) + 1e-12) if len(psd) > 1 else 0   # Yuksek frekanslardaki guc kaybi\n",
    "            spec_ent = entropy(psd + 1e-12)                                                             # Spektral entropi\n",
    "            spec_kurt = kurtosis(psd)                                                                   # Spektral carpiklik\n",
    "            diff_psd = np.diff(psd)\n",
    "            psd_sign_changes = np.diff(np.sign(diff_psd))\n",
    "            spec_pos_turning = np.sum(psd_sign_changes < 0)                                             # Spektral donuş noktasi sayisi\n",
    "            spec_roll_off = freqs[np.argmax(cumulative_power >= 0.85)] if len(psd) > 0 else 0           # Enerjinin %85'ine ulaşilan frekans\n",
    "            spec_roll_on = freqs[np.argmax(cumulative_power >= 0.05)] if len(psd) > 0 else 0            # Enerjinin %5'ine ulaşilan frekans\n",
    "            spec_skew = skew(psd)                                                                       # Spektral skewness\n",
    "            spec_slope = np.polyfit(freqs, psd, 1)[0] if len(psd) > 1 else 0                            # Spektral egim\n",
    "            spec_spread = np.sqrt(np.sum(psd * (freqs - spec_centroid)**2) / (np.sum(psd) + 1e-12))     # Spektral yayilma\n",
    "            \n",
    "            std = np.std(ch_signal)                                                                     # Standart sapma\n",
    "            sum_abs_diff = np.sum(np.abs(np.diff(ch_signal)))                                           # Ornekler arasi toplam fark\n",
    "            var = np.var(ch_signal)                                                                     # Varyans\n",
    "            \n",
    "            zero_crossings = np.sum(np.diff(np.sign(ch_signal)) != 0)\n",
    "            zcr = zero_crossings / len(ch_signal)                                                       # Sinyalin kac kez sifiri gectigi\n",
    "            \n",
    "            features = [\n",
    "                abs_energy, area_curve, autocorr, avg_power, centroid, hist_entropy,\n",
    "                fund_freq, hist_mode, human_energy, iqr_val, kurt_val, max_val,\n",
    "                max_psd, max_freq, mean_val, mad, mean_abs_diff, mean_diff, med_val,\n",
    "                med_abs_dev, med_abs_diff, med_diff, med_freq, min_val, neg_turning,\n",
    "                n_peaks, peak_dist, pos_turning, power_bandwidth, rms, signal_dist,\n",
    "                skew_val, slope, spec_centroid, spec_decrease, spec_ent,\n",
    "                spec_kurt, spec_pos_turning, spec_roll_off, spec_roll_on, spec_skew,\n",
    "                spec_slope, spec_spread, std, sum_abs_diff, var, zcr\n",
    "            ]\n",
    "            \n",
    "            feats.extend(features)\n",
    "            \n",
    "        feature_list.append(feats)\n",
    "        count += 1\n",
    "        \n",
    "    print(f\"ozellik cikarimi icin toplam {count} epoch işlendi.\")\n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8fe11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(psg_file, hyp_file, epoch_duration=30.0):\n",
    "    raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
    "    \n",
    "    annotations = mne.read_annotations(hyp_file)                                                        # Hypnogram dosyasindan etiketleri cikartiyoruz.\n",
    "    raw.set_annotations(annotations)\n",
    "    \n",
    "    stage_mapping = {                                                                                   # Olaylari mapliyoruz.\n",
    "        'Sleep stage W': 0,\n",
    "        'Sleep stage 1': 1,\n",
    "        'Sleep stage 2': 2,\n",
    "        'Sleep stage 3': 3,\n",
    "        'Sleep stage 4': 3,\n",
    "        'Sleep stage R': 4,\n",
    "        'Sleep stage ?': -1,\n",
    "        'Movement time': -1\n",
    "    }\n",
    "    \n",
    "    events, event_dict = mne.events_from_annotations(                                                   # Epochlari ve etiketleri olusturuyoruz.\n",
    "        raw, \n",
    "        event_id=stage_mapping,\n",
    "        chunk_duration=epoch_duration\n",
    "    )\n",
    "    \n",
    "    valid_events = [e for e in events if 0 <= e[2] <= 4]                                                # Gecerli uyku evrelerini filtreliyorum\n",
    "    \n",
    "    epochs = mne.Epochs(                                                                                # Epochlari olusturuyorum ve ozelliklerini cikartiyorum.\n",
    "        raw, \n",
    "        valid_events, \n",
    "        tmin=0.0, \n",
    "        tmax=epoch_duration - 1/raw.info['sfreq'],\n",
    "        baseline=None,\n",
    "        preload=True\n",
    "    )\n",
    "    \n",
    "    data = epochs.get_data()\n",
    "    features = extract_features_multi(data, raw.info['sfreq'])\n",
    "    labels = [e[2] for e in valid_events]\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c6fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_standard_scaler(X):              # Verilerimi 0-1 arasina standartize ediyorum.\n",
    "    mean = np.mean(X, axis=0)           # Her sutunun ortalamasi\n",
    "    std = np.std(X, axis=0)             # Her sutunun standart sapmasi\n",
    "    X_scaled = (X - mean) / std         # Standardizasyon formulu\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f2040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sleep_stages(psg_file, hyp_file):\n",
    "    import joblib\n",
    "\n",
    "    imputer = joblib.load('imputer.joblib')                                                 # Modelleri yukluyorum\n",
    "    selector = joblib.load('selector.joblib')\n",
    "    rf_model = joblib.load('random_forest_model.joblib')\n",
    "    xgb_model = joblib.load('xgboost_model.joblib')\n",
    "    mlp_model = load_model('mlp_model.h5')\n",
    "\n",
    "    features, y_true = preprocess_data(psg_file, hyp_file)                                  # Ozellik cikarimi ve scaling yapiyorum.\n",
    "    features_scaled = my_standard_scaler(features)\n",
    "    features_imputed = imputer.transform(features_scaled)\n",
    "\n",
    "    \n",
    "    features_selected = selector.transform(features_imputed)                                # SelectKBest ile en iyi 150 feature'ı aliyorum.\n",
    "\n",
    "    rf_pred = rf_model.predict(features_selected)                                           # Modellerle tahmin yapiyorum.\n",
    "    xgb_pred = xgb_model.predict(features_selected)\n",
    "    mlp_pred = np.argmax(mlp_model.predict(features_selected), axis=1)\n",
    "\n",
    "    stage_map = {0: 'Wake', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'REM'}                            # Performans ciktisi olusturuyorum.\n",
    "    \n",
    "    results = {\n",
    "        'true': [stage_map[l] for l in y_true],\n",
    "        'rf': [stage_map[p] for p in rf_pred],\n",
    "        'xgb': [stage_map[p] for p in xgb_pred],\n",
    "        'mlp': [stage_map[p] for p in mlp_pred]\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f324c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score\n",
    "def calculate_metrics(y_true, y_pred):                                                      # Performans verilerini elde ediyorum.\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    return acc, f1, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ff7e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İşleniyor: SC4102E0-PSG.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:5: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(annotations)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('Movement time'), np.str_('Sleep stage 1'), np.str_('Sleep stage 2'), np.str_('Sleep stage 3'), np.str_('Sleep stage ?'), np.str_('Sleep stage R'), np.str_('Sleep stage W')]\n",
      "Not setting metadata\n",
      "2857 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2857 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\2363082506.py:15: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozellik cikarimi icin toplam 2857 epoch işlendi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\924106973.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  X_scaled = (X - mean) / std         # Standardizasyon formulu\n",
      "c:\\Users\\EgeTERZI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: [ 13  60 107 147 154 163 178 194 201 216 225 226 241 248 257 263 272 281\n",
      " 288 295 304 310 319]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "İşleniyor: SC4111E0-PSG.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:5: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(annotations)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('Movement time'), np.str_('Sleep stage 1'), np.str_('Sleep stage 2'), np.str_('Sleep stage 3'), np.str_('Sleep stage 4'), np.str_('Sleep stage ?'), np.str_('Sleep stage R'), np.str_('Sleep stage W')]\n",
      "Not setting metadata\n",
      "2641 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2641 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\2363082506.py:15: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozellik cikarimi icin toplam 2641 epoch işlendi.\n",
      "\u001b[1m 1/83\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 64ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\924106973.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  X_scaled = (X - mean) / std         # Standardizasyon formulu\n",
      "c:\\Users\\EgeTERZI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: [ 13  60 107 147 154 163 178 194 201 216 225 226 241 248 257 263 272 281\n",
      " 288 295 304 310 319]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "İşleniyor: SC4112E0-PSG.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:5: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(annotations)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('Sleep stage 1'), np.str_('Sleep stage 2'), np.str_('Sleep stage 3'), np.str_('Sleep stage 4'), np.str_('Sleep stage ?'), np.str_('Sleep stage R'), np.str_('Sleep stage W')]\n",
      "Not setting metadata\n",
      "2780 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2780 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\2363082506.py:15: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozellik cikarimi icin toplam 2780 epoch işlendi.\n",
      "\u001b[1m 1/87\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 65ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\924106973.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  X_scaled = (X - mean) / std         # Standardizasyon formulu\n",
      "c:\\Users\\EgeTERZI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: [ 13  60 107 147 154 163 178 194 201 216 225 226 241 248 257 263 272 281\n",
      " 288 295 304 310 319]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "İşleniyor: SC4121E0-PSG.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:5: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(annotations)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('Sleep stage 1'), np.str_('Sleep stage 2'), np.str_('Sleep stage 3'), np.str_('Sleep stage 4'), np.str_('Sleep stage ?'), np.str_('Sleep stage R'), np.str_('Sleep stage W')]\n",
      "Not setting metadata\n",
      "2685 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2685 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\2363082506.py:15: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozellik cikarimi icin toplam 2685 epoch işlendi.\n",
      "\u001b[1m 1/84\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 61ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\924106973.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  X_scaled = (X - mean) / std         # Standardizasyon formulu\n",
      "c:\\Users\\EgeTERZI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: [ 13  60 107 147 154 163 178 194 201 216 225 226 241 248 257 263 272 281\n",
      " 288 295 304 310 319]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "İşleniyor: SC4131E0-PSG.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:2: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\3438200896.py:5: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(annotations)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('Sleep stage 1'), np.str_('Sleep stage 2'), np.str_('Sleep stage 3'), np.str_('Sleep stage 4'), np.str_('Sleep stage ?'), np.str_('Sleep stage R'), np.str_('Sleep stage W')]\n",
      "Not setting metadata\n",
      "2814 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2814 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\2363082506.py:15: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozellik cikarimi icin toplam 2814 epoch işlendi.\n",
      "\u001b[1m 1/88\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 62ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_15204\\924106973.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  X_scaled = (X - mean) / std         # Standardizasyon formulu\n",
      "c:\\Users\\EgeTERZI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: [ 13  60 107 147 154 163 178 194 201 216 225 226 241 248 257 263 272 281\n",
      " 288 295 304 310 319]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Random Forest Performansı:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.24      0.36      0.29       253\n",
      "          N2       0.84      0.72      0.78      2465\n",
      "          N3       0.74      0.64      0.69       519\n",
      "         REM       0.79      0.60      0.68       938\n",
      "        Wake       0.94      0.99      0.96      9602\n",
      "\n",
      "    accuracy                           0.89     13777\n",
      "   macro avg       0.71      0.66      0.68     13777\n",
      "weighted avg       0.89      0.89      0.89     13777\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9509   19   34    6   34]\n",
      " [  89   90   38    0   36]\n",
      " [ 379  126 1770  109   81]\n",
      " [  52    0  131  334    2]\n",
      " [ 122  135  122    0  559]]\n",
      "XGBoost Performansı:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.32      0.42      0.36       253\n",
      "          N2       0.86      0.71      0.77      2465\n",
      "          N3       0.74      0.66      0.70       519\n",
      "         REM       0.82      0.62      0.70       938\n",
      "        Wake       0.93      0.99      0.96      9602\n",
      "\n",
      "    accuracy                           0.89     13777\n",
      "   macro avg       0.73      0.68      0.70     13777\n",
      "weighted avg       0.89      0.89      0.89     13777\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9503   18   42    8   31]\n",
      " [  91  105   34    0   23]\n",
      " [ 430  114 1741  109   71]\n",
      " [  65    1  108  344    1]\n",
      " [ 156   94  110    1  577]]\n",
      "MLP Performansı:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.30      0.57      0.39       253\n",
      "          N2       0.85      0.73      0.79      2465\n",
      "          N3       0.63      0.73      0.68       519\n",
      "         REM       0.73      0.68      0.71       938\n",
      "        Wake       0.97      0.98      0.97      9602\n",
      "\n",
      "    accuracy                           0.90     13777\n",
      "   macro avg       0.70      0.74      0.71     13777\n",
      "weighted avg       0.90      0.90      0.90     13777\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9369   81   27   39   86]\n",
      " [  28  143   47    0   35]\n",
      " [ 214  148 1810  184  109]\n",
      " [  15    4  116  379    5]\n",
      " [  77  100  120    0  641]]\n",
      "MODEL PERFORMANS KARŞILAŞTIRMASI:\n",
      "RF:    Accuracy=0.8900, F1=0.6791, Kappa=0.7578\n",
      "XGB:   Accuracy=0.8906, F1=0.6990, Kappa=0.7570\n",
      "MLP:   Accuracy=0.8958, F1=0.7071, Kappa=0.7807\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_dir = \"./SleepData/Sleep_EDF_Testing_Data\"                                         # Test dosyamizi aliyorum.\n",
    "    psg_files = glob.glob(os.path.join(data_dir, \"*0-PSG.edf\"))\n",
    "    \n",
    "    all_true = []                                                                           # Tum modeller icin toplu sonuclari tutuyorum.\n",
    "    all_rf_pred = []\n",
    "    all_xgb_pred = []\n",
    "    all_mlp_pred = []\n",
    "    \n",
    "    tekVeriIcinCalistir=False                                                               # True oldugunda klasordeki sadece 1 veriyi okur ve test yapar. Exact bir veri icin asagidaki 0-PSG.edf'in ismini ozellestirebilirsiniz.\n",
    "    for psg_file in psg_files:                                                              # Dosya ciftlerini seciyorum.\n",
    "        hyp_file = psg_file.replace('0-PSG.edf', 'C-Hypnogram.edf')\n",
    "        \n",
    "        if not os.path.exists(hyp_file):\n",
    "            print(f\"Hipnogram dosyası bulunamadı: {hyp_file}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"İşleniyor: {os.path.basename(psg_file)}\")\n",
    "        results = predict_sleep_stages(psg_file, hyp_file)\n",
    "        \n",
    "        all_true.extend(results['true'])\n",
    "        all_rf_pred.extend(results['rf'])\n",
    "        all_xgb_pred.extend(results['xgb'])\n",
    "        all_mlp_pred.extend(results['mlp'])\n",
    "\n",
    "        if (tekVeriIcinCalistir==True): break\n",
    "                                                                                            # Performans ciktilarini  hesapliyorum.\n",
    "    print(\"Random Forest Performansı:\")\n",
    "    print(classification_report(all_true, all_rf_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_rf_pred, labels=['Wake', 'N1', 'N2', 'N3', 'REM']))\n",
    "    \n",
    "    print(\"XGBoost Performansı:\")\n",
    "    print(classification_report(all_true, all_xgb_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_xgb_pred, labels=['Wake', 'N1', 'N2', 'N3', 'REM']))\n",
    "    \n",
    "    print(\"MLP Performansı:\")\n",
    "    print(classification_report(all_true, all_mlp_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_mlp_pred, labels=['Wake', 'N1', 'N2', 'N3', 'REM']))\n",
    "\n",
    "    rf_metrics = calculate_metrics(all_true, all_rf_pred)                                   # Modellerin performansini karsilastiriyorum.\n",
    "    xgb_metrics = calculate_metrics(all_true, all_xgb_pred)\n",
    "    mlp_metrics = calculate_metrics(all_true, all_mlp_pred)\n",
    "\n",
    "    print(\"MODEL PERFORMANS KARŞILAŞTIRMASI:\")\n",
    "    print(f\"RF:    Accuracy={rf_metrics[0]:.4f}, F1={rf_metrics[1]:.4f}, Kappa={rf_metrics[2]:.4f}\")\n",
    "    print(f\"XGB:   Accuracy={xgb_metrics[0]:.4f}, F1={xgb_metrics[1]:.4f}, Kappa={xgb_metrics[2]:.4f}\")\n",
    "    print(f\"MLP:   Accuracy={mlp_metrics[0]:.4f}, F1={mlp_metrics[1]:.4f}, Kappa={mlp_metrics[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
