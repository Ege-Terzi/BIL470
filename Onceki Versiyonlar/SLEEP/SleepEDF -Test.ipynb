{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee813201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy import stats\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd57375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis, entropy\n",
    "\n",
    "def extract_features_multi(data, sfreq):                                    # Sinyallere ait ozellikleri burada cikartiyoruz. data: np.array, shape (n_epochs, n_channels, n_times), sfreq: ornekleme hizi (Hz)\n",
    "                                                                            # Orijinal kodla ayni\n",
    "    feature_list = []   \n",
    "    count=0                                                                 # Islenen toplam epoch sayisi.\n",
    "\n",
    "    for epoch in data:                                                      # Her epoch icin dongu donuyoruz ve featurelarini cikartiyoruz.\n",
    "        feats = []\n",
    "        for ch_signal in epoch:                                             # Her kanal icin dongu\n",
    "\n",
    "            mean = np.mean(ch_signal)                                       # Ortalama\n",
    "            median = np.median(ch_signal)                                   # Medyan\n",
    "            variance = np.var(ch_signal)                                    # Varyans\n",
    "            min_val = np.min(ch_signal)                                     # Minimum deger\n",
    "            max_val = np.max(ch_signal)                                     # Maksimum deger\n",
    "            ptp = max_val - min_val                                         # Tepe araligi\n",
    "            \n",
    "            feats.extend([mean, median, variance, min_val, max_val, ptp])\n",
    "            \n",
    "            autocorr = np.correlate(ch_signal, ch_signal, mode='full')[len(ch_signal)-1:len(ch_signal)+5]       # Ilk 5 gecikme icin otokorelasyon degerleri\n",
    "            feats.extend(autocorr[1:6])\n",
    "            \n",
    "            t = np.arange(len(ch_signal))                                   # Zaman vektoru\n",
    "            slope = np.polyfit(t, ch_signal, 1)[0]                          # Egim hesabi\n",
    "            feats.append(slope)\n",
    "            \n",
    "            hist, _ = np.histogram(ch_signal, bins=10, density=True)        # Entropi hesabi\n",
    "            ent = entropy(hist)\n",
    "            feats.append(ent)\n",
    "            \n",
    "            rms = np.sqrt(np.mean(ch_signal**2))                            # Root Mean Square frekans hesabi\n",
    "            feats.append(rms)\n",
    "            \n",
    "            zcr = np.sum(np.diff(np.sign(ch_signal)) != 0) / len(ch_signal)     # Zero Crossing Rate hesabi\n",
    "            feats.append(zcr)\n",
    "            \n",
    "            s = skew(ch_signal)                                            # Skewness ve kurtosis hesabi\n",
    "            k = kurtosis(ch_signal)\n",
    "            feats.extend([s, k])\n",
    "            \n",
    "            count+=1\n",
    "        feature_list.append(feats)\n",
    "\n",
    "    print (f\"Özellik çıkarımı için toplam {count} epoch işleniyor...\")\n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8fe11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(psg_file, hyp_file, epoch_duration=30.0):\n",
    "    raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
    "    \n",
    "    wanted = ['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'EMG submental']                             # Kullanacagimiz kanallari seciyoruz.\n",
    "    use_chs = [ch for ch in raw.ch_names if ch in wanted]\n",
    "    raw.pick_channels(use_chs)\n",
    "    \n",
    "    annotations = mne.read_annotations(hyp_file)                                                        # Hypnogram dosyasindan etiketleri cikartiyoruz.\n",
    "    raw.set_annotations(annotations)\n",
    "    \n",
    "    stage_mapping = {                                                                                   # Olaylari mapliyoruz.\n",
    "        'Sleep stage W': 0,\n",
    "        'Sleep stage 1': 1,\n",
    "        'Sleep stage 2': 2,\n",
    "        'Sleep stage 3': 3,\n",
    "        'Sleep stage 4': 3,\n",
    "        'Sleep stage R': 4,\n",
    "        'Sleep stage ?': -1,\n",
    "        'Movement time': -1\n",
    "    }\n",
    "    \n",
    "    \n",
    "    events, event_dict = mne.events_from_annotations(                                                   # Epochlari ve etiketleri olusturuyoruz.\n",
    "        raw, \n",
    "        event_id=stage_mapping,\n",
    "        chunk_duration=epoch_duration\n",
    "    )\n",
    "    \n",
    "    valid_events = [e for e in events if 0 <= e[2] <= 4]                                                # Gecerli uyku evrelerini filtreliyorum\n",
    "    \n",
    "    epochs = mne.Epochs(                                                                                # Epochlari olusturuyorum ve ozelliklerini cikartiyorum.\n",
    "        raw, \n",
    "        valid_events, \n",
    "        tmin=0.0, \n",
    "        tmax=epoch_duration - 1/raw.info['sfreq'],\n",
    "        baseline=None,\n",
    "        preload=True\n",
    "    )\n",
    "    \n",
    "    data = epochs.get_data()\n",
    "    features = extract_features_multi(data, raw.info['sfreq'])\n",
    "    labels = [e[2] for e in valid_events]\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c6fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_standard_scaler(X):              # Verilerimi 0-1 arasina standartize ediyorum.\n",
    "    mean = np.mean(X, axis=0)           # Her sutunun ortalamasi\n",
    "    std = np.std(X, axis=0)             # Her sutunun standart sapmasi\n",
    "    X_scaled = (X - mean) / std         # Standardizasyon formulu\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f2040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sleep_stages(psg_file, hyp_file):\n",
    "    features, y_true = preprocess_data(psg_file, hyp_file)                                  # Verinin ozelliklerini ve etiketlerini hazirliyorum.\n",
    "    \n",
    "    features_scaled = my_standard_scaler(features)                                          # Ozellikleri olceklendiriyorum.\n",
    "    \n",
    "    rf_model = joblib.load('random_forest_model.joblib')                                    # Modelleri yukluyorum\n",
    "    xgb_model = joblib.load('xgboost_model.joblib')\n",
    "    lstm_model = load_model('lstm_model.h5')\n",
    "    mlp_model = load_model('mlp_model.h5')\n",
    "    \n",
    "    rf_pred = rf_model.predict(features_scaled)                                             # Yuklenen modellerle tahmin yapiyorum.\n",
    "    xgb_pred = xgb_model.predict(features_scaled)\n",
    "\n",
    "    timesteps = 1\n",
    "    features_per_timestep = features_scaled.shape[1] // timesteps\n",
    "    X_reshaped = features_scaled.reshape(-1, timesteps, features_per_timestep)\n",
    "    lstm_pred = np.argmax(lstm_model.predict(X_reshaped), axis=1)                           # LSTM icin veriyi yeniden sekillendiriyorum.\n",
    "    \n",
    "    mlp_pred = np.argmax(mlp_model.predict(features_scaled), axis=1)\n",
    "    \n",
    "    stage_map = {0: 'Wake', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'REM'}                            # Performans ciktisi olusturuyorum.\n",
    "    \n",
    "    results = {\n",
    "        'true': [stage_map[l] for l in y_true],\n",
    "        'rf': [stage_map[p] for p in rf_pred],\n",
    "        'xgb': [stage_map[p] for p in xgb_pred],\n",
    "        'lstm': [stage_map[p] for p in lstm_pred],\n",
    "        'mlp': [stage_map[p] for p in mlp_pred]\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f324c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score\n",
    "def calculate_metrics(y_true, y_pred):                                                      # Performans verilerini elde ediyorum.\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    return acc, f1, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44ff7e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İşleniyor: SC4102E0-PSG.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:9: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(annotations)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('Movement time'), np.str_('Sleep stage 1'), np.str_('Sleep stage 2'), np.str_('Sleep stage 3'), np.str_('Sleep stage ?'), np.str_('Sleep stage R'), np.str_('Sleep stage W')]\n",
      "Not setting metadata\n",
      "2857 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2857 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Özellik çıkarımı için toplam 11428 epoch işleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "İşleniyor: SC4111E0-PSG.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:9: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(annotations)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('Movement time'), np.str_('Sleep stage 1'), np.str_('Sleep stage 2'), np.str_('Sleep stage 3'), np.str_('Sleep stage 4'), np.str_('Sleep stage ?'), np.str_('Sleep stage R'), np.str_('Sleep stage W')]\n",
      "Not setting metadata\n",
      "2641 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2641 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Özellik çıkarımı için toplam 10564 epoch işleniyor...\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "İşleniyor: SC4112E0-PSG.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:9: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(annotations)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('Sleep stage 1'), np.str_('Sleep stage 2'), np.str_('Sleep stage 3'), np.str_('Sleep stage 4'), np.str_('Sleep stage ?'), np.str_('Sleep stage R'), np.str_('Sleep stage W')]\n",
      "Not setting metadata\n",
      "2780 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2780 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Özellik çıkarımı için toplam 11120 epoch işleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "İşleniyor: SC4121E0-PSG.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:9: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(annotations)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('Sleep stage 1'), np.str_('Sleep stage 2'), np.str_('Sleep stage 3'), np.str_('Sleep stage 4'), np.str_('Sleep stage ?'), np.str_('Sleep stage R'), np.str_('Sleep stage W')]\n",
      "Not setting metadata\n",
      "2685 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2685 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Özellik çıkarımı için toplam 10740 epoch işleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "İşleniyor: SC4131E0-PSG.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:2: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(psg_file, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_13704\\444076516.py:9: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(annotations)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('Sleep stage 1'), np.str_('Sleep stage 2'), np.str_('Sleep stage 3'), np.str_('Sleep stage 4'), np.str_('Sleep stage ?'), np.str_('Sleep stage R'), np.str_('Sleep stage W')]\n",
      "Not setting metadata\n",
      "2814 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2814 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Özellik çıkarımı için toplam 11256 epoch işleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Random Forest Performansı:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.51      0.36      0.42       253\n",
      "          N2       0.78      0.79      0.79      2465\n",
      "          N3       0.72      0.63      0.67       519\n",
      "         REM       0.53      0.70      0.60       938\n",
      "        Wake       0.97      0.95      0.96      9602\n",
      "\n",
      "    accuracy                           0.88     13777\n",
      "   macro avg       0.70      0.68      0.69     13777\n",
      "weighted avg       0.89      0.88      0.88     13777\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9102   55  134   15  296]\n",
      " [  37   90   61    0   65]\n",
      " [ 179   19 1950  110  207]\n",
      " [  48    0  136  327    8]\n",
      " [  49   13  221    0  655]]\n",
      "XGBoost Performansı:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.30      0.46      0.36       253\n",
      "          N2       0.78      0.75      0.77      2465\n",
      "          N3       0.72      0.66      0.69       519\n",
      "         REM       0.69      0.58      0.63       938\n",
      "        Wake       0.95      0.97      0.96      9602\n",
      "\n",
      "    accuracy                           0.88     13777\n",
      "   macro avg       0.69      0.68      0.68     13777\n",
      "weighted avg       0.88      0.88      0.88     13777\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9275   60  132    4  131]\n",
      " [  31  116   71    0   35]\n",
      " [ 303   95 1853  129   85]\n",
      " [  36    0  141  342    0]\n",
      " [ 108  115  166    2  547]]\n",
      "LSTM Performansı:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.29      0.31      0.30       253\n",
      "          N2       0.74      0.78      0.76      2465\n",
      "          N3       0.63      0.75      0.68       519\n",
      "         REM       0.55      0.68      0.61       938\n",
      "        Wake       0.97      0.92      0.94      9602\n",
      "\n",
      "    accuracy                           0.86     13777\n",
      "   macro avg       0.63      0.69      0.66     13777\n",
      "weighted avg       0.87      0.86      0.86     13777\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8789  138  285   54  336]\n",
      " [  28   78   68    0   79]\n",
      " [ 205   37 1935  178  110]\n",
      " [  13    0  116  390    0]\n",
      " [  62   20  216    1  639]]\n",
      "MLP Performansı:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.38      0.50      0.43       253\n",
      "          N2       0.75      0.83      0.79      2465\n",
      "          N3       0.76      0.69      0.72       519\n",
      "         REM       0.65      0.57      0.61       938\n",
      "        Wake       0.96      0.94      0.95      9602\n",
      "\n",
      "    accuracy                           0.88     13777\n",
      "   macro avg       0.70      0.71      0.70     13777\n",
      "weighted avg       0.88      0.88      0.88     13777\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9067  122  192   19  202]\n",
      " [  24  127   76    0   26]\n",
      " [ 232   47 2037   95   54]\n",
      " [  19    4  138  357    1]\n",
      " [ 100   34  269    1  534]]\n",
      "MODEL PERFORMANS KARŞILAŞTIRMASI:\n",
      "RF:    Accuracy=0.8800, F1=0.6877, Kappa=0.7519\n",
      "XGB:   Accuracy=0.8807, F1=0.6812, Kappa=0.7462\n",
      "LSTM:  Accuracy=0.8588, F1=0.6577, Kappa=0.7163\n",
      "MLP:   Accuracy=0.8799, F1=0.7002, Kappa=0.7504\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_dir = \"./Sleep_EDF_Testing_Data\"                                                   # Test dosyamizi aliyorum.\n",
    "    psg_files = glob.glob(os.path.join(data_dir, \"*0-PSG.edf\"))\n",
    "    \n",
    "    all_true = []                                                                           # Tum modeller icin toplu sonuclari tutuyorum.\n",
    "    all_rf_pred = []\n",
    "    all_xgb_pred = []\n",
    "    all_lstm_pred = []\n",
    "    all_mlp_pred = []\n",
    "    \n",
    "    for psg_file in psg_files:                                                              # Dosya ciftlerini seciyorum.\n",
    "        hyp_file = psg_file.replace('0-PSG.edf', 'C-Hypnogram.edf')\n",
    "        \n",
    "        if not os.path.exists(hyp_file):\n",
    "            print(f\"Hipnogram dosyası bulunamadı: {hyp_file}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"İşleniyor: {os.path.basename(psg_file)}\")\n",
    "        results = predict_sleep_stages(psg_file, hyp_file)\n",
    "        \n",
    "        all_true.extend(results['true'])\n",
    "        all_rf_pred.extend(results['rf'])\n",
    "        all_xgb_pred.extend(results['xgb'])\n",
    "        all_lstm_pred.extend(results['lstm'])\n",
    "        all_mlp_pred.extend(results['mlp'])\n",
    "                                                                     # Performans ciktilarini  hesapliyorum.\n",
    "    print(\"Random Forest Performansı:\")\n",
    "    print(classification_report(all_true, all_rf_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_rf_pred, labels=['Wake', 'N1', 'N2', 'N3', 'REM']))\n",
    "    \n",
    "    print(\"XGBoost Performansı:\")\n",
    "    print(classification_report(all_true, all_xgb_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_xgb_pred, labels=['Wake', 'N1', 'N2', 'N3', 'REM']))\n",
    "    \n",
    "    print(\"LSTM Performansı:\")\n",
    "    print(classification_report(all_true, all_lstm_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_lstm_pred, labels=['Wake', 'N1', 'N2', 'N3', 'REM']))\n",
    "    \n",
    "    print(\"MLP Performansı:\")\n",
    "    print(classification_report(all_true, all_mlp_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_mlp_pred, labels=['Wake', 'N1', 'N2', 'N3', 'REM']))\n",
    "\n",
    "    rf_metrics = calculate_metrics(all_true, all_rf_pred)           # Modellerin performansini karsilastiriyorum.\n",
    "    xgb_metrics = calculate_metrics(all_true, all_xgb_pred)\n",
    "    lstm_metrics = calculate_metrics(all_true, all_lstm_pred)\n",
    "    mlp_metrics = calculate_metrics(all_true, all_mlp_pred)\n",
    "\n",
    "    print(\"MODEL PERFORMANS KARŞILAŞTIRMASI:\")\n",
    "    print(f\"RF:    Accuracy={rf_metrics[0]:.4f}, F1={rf_metrics[1]:.4f}, Kappa={rf_metrics[2]:.4f}\")\n",
    "    print(f\"XGB:   Accuracy={xgb_metrics[0]:.4f}, F1={xgb_metrics[1]:.4f}, Kappa={xgb_metrics[2]:.4f}\")\n",
    "    print(f\"LSTM:  Accuracy={lstm_metrics[0]:.4f}, F1={lstm_metrics[1]:.4f}, Kappa={lstm_metrics[2]:.4f}\")\n",
    "    print(f\"MLP:   Accuracy={mlp_metrics[0]:.4f}, F1={mlp_metrics[1]:.4f}, Kappa={mlp_metrics[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
