{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4338abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from scipy import stats\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, cohen_kappa_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6834122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks, welch\n",
    "from scipy.stats import entropy, kurtosis, skew, iqr\n",
    "\n",
    "def extract_emotion_features(data, sfreq):\n",
    "    feature_list = []\n",
    "    count = 0\n",
    "    \n",
    "    # Zaman serisinde ozellik cikarimi yapiyorum. Buradaki ozniteliklerin cogunu TSFEL: Time Series Feature Extraction Library makalesinden aldim.\n",
    "\n",
    "    for epoch in data:\n",
    "        feats = []\n",
    "        for ch_signal in epoch:\n",
    "            t = np.arange(len(ch_signal))\n",
    "            abs_energy = np.sum(ch_signal**2)                                                           # Sinyalin toplam enerjisi, guc olcusu\n",
    "            area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n",
    "            \n",
    "            autocorr = np.corrcoef(ch_signal[:-1], ch_signal[1:])[0, 1] if np.std(ch_signal) > 0 else 0 # Sinyalin kendisiyle bir gecikmeyle olan korelasyonu\n",
    "            \n",
    "            avg_power = np.mean(ch_signal**2)                                                           # Ortalama guc\n",
    "            centroid = np.sum(t * np.abs(ch_signal)) / (np.sum(np.abs(ch_signal)) + 1e-12)              # Sinyal agirlik merkezi\n",
    "            \n",
    "            hist, _ = np.histogram(ch_signal, bins=10, density=True)\n",
    "            hist_entropy = entropy(hist + 1e-12)                                                        # Sinyal genlik dagiliminin duzensizligi\n",
    "            \n",
    "            freqs, psd = welch(ch_signal, sfreq, nperseg=min(256, len(ch_signal)))\n",
    "            psd /= np.sum(psd) + 1e-12                                                                  # Frekanslara gore enerji dagilimi\n",
    "            \n",
    "            fund_freq = freqs[np.argmax(psd)] if len(psd) > 0 else 0                                    # En yuksek guce sahip frekans bileşeni\n",
    "            \n",
    "            hist_vals, hist_bins = np.histogram(ch_signal, bins=10)\n",
    "            hist_mode = hist_bins[np.argmax(hist_vals)]                                                 # En cok gorulen genlik degeri\n",
    "            \n",
    "            human_energy = np.sum(psd[(freqs >= 0.5) & (freqs <= 40)])                                  # Insan EEG bandindaki enerji\n",
    "            iqr_val = iqr(ch_signal)                                                                    # Sinyalin orta %50'sinin yayilimi\n",
    "            kurt_val = kurtosis(ch_signal)                                                              # Carpiklik, uc deger yogunlugu\n",
    "            \n",
    "            max_val = np.max(ch_signal)                                                                 # Maksimum deger\n",
    "            max_psd = np.max(psd)                                                                       # Maksimum guc\n",
    "            max_freq = freqs[-1]                                                                         # En yuksek olculebilir frekans\n",
    "            \n",
    "            mean_val = np.mean(ch_signal)                                                               # Ortalama deger\n",
    "            mad = np.mean(np.abs(ch_signal - mean_val))                                                 # Ortalama mutlak sapma\n",
    "            mean_abs_diff = np.mean(np.abs(np.diff(ch_signal)))                                         # Komşu ornekler arasindaki ortalama mutlak fark\n",
    "            mean_diff = np.mean(np.diff(ch_signal))                                                     # Komşu ornekler arasindaki ortalama fark\n",
    "            \n",
    "            med_val = np.median(ch_signal)                                                              # Medyan deger\n",
    "            med_abs_dev = np.median(np.abs(ch_signal - med_val))                                        # Medyan mutlak sapma\n",
    "            med_abs_diff = np.median(np.abs(np.diff(ch_signal)))                                        # Medyan komşu mutlak farki\n",
    "            med_diff = np.median(np.diff(ch_signal))                                                    # Medyan komşu farki\n",
    "            cumulative_power = np.cumsum(psd)\n",
    "            med_freq = freqs[np.argmax(cumulative_power >= 0.5)] if len(psd) > 0 else 0                 # Medyan frekans\n",
    "            \n",
    "            min_val = np.min(ch_signal)                                                                 # Minimum deger\n",
    "            \n",
    "            diff_signal = np.diff(ch_signal)\n",
    "            sign_changes = np.diff(np.sign(diff_signal))\n",
    "            neg_turning = np.sum(sign_changes > 0)                                                      # Negatif egimden pozitif egime geciş sayisi\n",
    "            pos_turning = np.sum(sign_changes < 0)                                                      # Pozitif egimden negatif egime geciş sayisi\n",
    "            peaks, _ = find_peaks(ch_signal)\n",
    "            n_peaks = len(peaks)                                                                        # Tepe sayisi\n",
    "            peak_dist = np.mean(np.diff(peaks)) if n_peaks > 1 else 0                                   # Tepeler arasi ortalama mesafe\n",
    "            \n",
    "            if len(psd) > 0:\n",
    "                peak_psd = np.max(psd)\n",
    "                mask = psd >= (peak_psd / 2)\n",
    "                try:\n",
    "                    power_bandwidth = freqs[mask][-1] - freqs[mask][0]                                  # Gucun %50'sinden fazlasini iceren frekans araligi\n",
    "                except:\n",
    "                    power_bandwidth = 0\n",
    "            else:\n",
    "                power_bandwidth = 0\n",
    "                \n",
    "            rms = np.sqrt(avg_power)                                                                    \n",
    "            signal_dist = np.sum(np.abs(ch_signal))                                                     # Mutlak genlik toplami\n",
    "            skew_val = skew(ch_signal)                                                                  # Simetri olcusu\n",
    "            slope = np.polyfit(t, ch_signal, 1)[0]                                                      # Lineer egim, trend\n",
    "            \n",
    "            spec_centroid = np.sum(freqs * psd) / (np.sum(psd) + 1e-12)                                 # Spektral agirlik merkezi\n",
    "            spec_decrease = np.sum((psd[1:] - psd[0]) / np.arange(1, len(psd))) / (np.sum(psd[1:]) + 1e-12) if len(psd) > 1 else 0   # Yuksek frekanslardaki guc kaybi\n",
    "            spec_ent = entropy(psd + 1e-12)                                                             # Spektral entropi\n",
    "            spec_kurt = kurtosis(psd)                                                                   # Spektral carpiklik\n",
    "            diff_psd = np.diff(psd)\n",
    "            psd_sign_changes = np.diff(np.sign(diff_psd))\n",
    "            spec_pos_turning = np.sum(psd_sign_changes < 0)                                             # Spektral donuş noktasi sayisi\n",
    "            spec_roll_off = freqs[np.argmax(cumulative_power >= 0.85)] if len(psd) > 0 else 0           # Enerjinin %85'ine ulaşilan frekans\n",
    "            spec_roll_on = freqs[np.argmax(cumulative_power >= 0.05)] if len(psd) > 0 else 0            # Enerjinin %5'ine ulaşilan frekans\n",
    "            spec_skew = skew(psd)                                                                       # Spektral skewness\n",
    "            spec_slope = np.polyfit(freqs, psd, 1)[0] if len(psd) > 1 else 0                            # Spektral egim\n",
    "            spec_spread = np.sqrt(np.sum(psd * (freqs - spec_centroid)**2) / (np.sum(psd) + 1e-12))     # Spektral yayilma\n",
    "            \n",
    "            std = np.std(ch_signal)                                                                     # Standart sapma\n",
    "            sum_abs_diff = np.sum(np.abs(np.diff(ch_signal)))                                           # Ornekler arasi toplam fark\n",
    "            var = np.var(ch_signal)                                                                     # Varyans\n",
    "            \n",
    "            zero_crossings = np.sum(np.diff(np.sign(ch_signal)) != 0)\n",
    "            zcr = zero_crossings / len(ch_signal)                                                       # Sinyalin kac kez sifiri gectigi\n",
    "            \n",
    "            features = [\n",
    "                abs_energy, area_curve, autocorr, avg_power, centroid, hist_entropy,\n",
    "                fund_freq, hist_mode, human_energy, iqr_val, kurt_val, max_val,\n",
    "                max_psd, max_freq, mean_val, mad, mean_abs_diff, mean_diff, med_val,\n",
    "                med_abs_dev, med_abs_diff, med_diff, med_freq, min_val, neg_turning,\n",
    "                n_peaks, peak_dist, pos_turning, power_bandwidth, rms, signal_dist,\n",
    "                skew_val, slope, spec_centroid, spec_decrease, spec_ent,\n",
    "                spec_kurt, spec_pos_turning, spec_roll_off, spec_roll_on, spec_skew,\n",
    "                spec_slope, spec_spread, std, sum_abs_diff, var, zcr\n",
    "            ]\n",
    "            \n",
    "            feats.extend(features)\n",
    "            \n",
    "        feature_list.append(feats)\n",
    "        count += 1\n",
    "        \n",
    "    print(f\"ozellik cikarimi icin toplam {count} epoch işlendi.\")\n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511650b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'ibeg': 0, 'iend': 1, 'rsrt': 2, 'fixl': 3,\n",
    "    'quiz': 4, 'qdon': 5, 'base': 6, 'bend': 7, 'trno': 8,\n",
    "    'fixL': 9, 'stm': 10, 'clic': 11, 'vlnc': 12, 'arsl': 13,\n",
    "    'dmns': 14, 'lkng': 15, 'fmrt': 16, 'relv': 17, 'cate': 18,\n",
    "    'IBEG': 0, 'IEND': 1, 'puse': 19, 'boundary': 20, 'stop': 21,\n",
    "    'baseline': 22,'baseend': 23,'trialno': 24,'fixation loop': 25,\n",
    "    'neutral_1_1': 26,'valence': 27,'arousal': 13,'dominance': 14,'liking': 15,\n",
    "    'familiarity': 16,'relevance': 17,'3_2': 28,'click': 29,\n",
    "    'impedances begin': 30,'emotion_categ': 31,'impedances end': 32,'stop event': 33\n",
    "}\n",
    "def preprocess_emotion_data(eeg_file, event_file, epoch_duration=2.0):\n",
    "    try:\n",
    "        raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n",
    "        events_df = pd.read_csv(event_file, sep='\\t')\n",
    "        \n",
    "        events = []\n",
    "        for _, row in events_df.iterrows():                                                             # Etiketleri sayisallastiriyorum\n",
    "            sample = int(row['onset'] * raw.info['sfreq']/1000)\n",
    "            label_str = str(row['trial_type']).lower().strip()\n",
    "            label = label_mapping.get(label_str, -1)\n",
    "            if label >= 0:\n",
    "                events.append([sample, 0, label])\n",
    "        \n",
    "        events_array = np.array(events, dtype=np.int64)\n",
    "        \n",
    "        epochs = mne.Epochs(                                                                            # Epochlari olusturuyorum.\n",
    "            raw,\n",
    "            events_array,\n",
    "            tmin=0.0,\n",
    "            tmax=epoch_duration,\n",
    "            baseline=None,\n",
    "            preload=True,\n",
    "            reject_by_annotation=False\n",
    "        )\n",
    "        \n",
    "        data = epochs.get_data()                                                                        # Epoch verilerinin ozelliklerini cikartiyorum.\n",
    "        features = extract_emotion_features(data, raw.info['sfreq'])    \n",
    "        labels = epochs.events[:, -1]\n",
    "        \n",
    "        return features, labels\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {eeg_file}: {str(e)}\")\n",
    "        return np.array([]), np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29cbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_standard_scaler(X):              # Verilerimi 0-1 arasina standartize ediyorum.\n",
    "    mean = np.mean(X, axis=0)           # Her sutunun ortalamasi\n",
    "    std = np.std(X, axis=0)             # Her sutunun standart sapmasi\n",
    "    X_scaled = (X - mean) / std         # Standardizasyon formulu\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecba96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "def predict_emotions(eeg_file, event_file):\n",
    "    features, true_labels = preprocess_emotion_data(eeg_file, event_file)                               # Veriyi onisleme uyguluyorum.\n",
    "    if len(features) == 0:\n",
    "        return {}\n",
    "    imputer = joblib.load('imputer.joblib')\n",
    "    selector = joblib.load('selector.joblib')\n",
    "\n",
    "    features_imputed = imputer.transform(features)\n",
    "    features_selected = selector.transform(features_imputed)\n",
    "    features_scaled = my_standard_scaler(features_selected)                                                      # Veriyi standartize ediyorum.\n",
    "    \n",
    "    rf_model = joblib.load('random_forest_model.joblib')                                                # Modelleri yukluyorum.\n",
    "    xgb_model = joblib.load('xgboost_model.joblib')\n",
    "    mlp_model = load_model('mlp_model.h5')\n",
    "    \n",
    "    rf_pred = rf_model.predict(features_scaled)                                                         # Tahmin yaptiriyorum.\n",
    "    xgb_pred = xgb_model.predict(features_scaled)\n",
    "    mlp_pred = np.argmax(mlp_model.predict(features_scaled), axis=1)\n",
    "\n",
    "    mapping_inverse = {v: k for k, v in label_mapping.items()}                                          # Simdi tersten map ediyoruz, hata aliyordum burayi da ChatGPT'den aldim.\n",
    "    true_labels_str = [mapping_inverse.get(x, 'UNKNOWN') for x in true_labels]\n",
    "    rf_pred_str = [mapping_inverse.get(x, 'UNKNOWN') for x in rf_pred]\n",
    "    xgb_pred_str = [mapping_inverse.get(x, 'UNKNOWN') for x in xgb_pred]\n",
    "    mlp_pred_str = [mapping_inverse.get(x, 'UNKNOWN') for x in mlp_pred]\n",
    "                                                                      \n",
    "    results = {                                                                                         # Labellari decode ediyoruz.\n",
    "        'true': true_labels_str,\n",
    "        'rf': rf_pred_str,\n",
    "        'xgb': xgb_pred_str,\n",
    "        'mlp': mlp_pred_str\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebaa9e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):                                          # Performans verilerini elde ediyorum.\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    return acc, f1, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6787f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: sub-mit081_task-Emotion_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_9856\\700143633.py:14: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "pns: ['ECG', 'EMG', 'EMG_2']\n",
      "  raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "135 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 135 events and 501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_9856\\700143633.py:14: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_9856\\4259630819.py:15: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozellik cikarimi icin toplam 135 epoch işlendi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EgeTERZI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: [  13   60  107  154  201  248  295  342  389  436  483  530  577  624\n",
      "  671  718  765  812  859  906  953 1000 1047 1094 1141 1188 1235 1282\n",
      " 1329 1376 1423 1470 1517 1564 1611 1658 1705 1752 1799 1846 1893 1940\n",
      " 1987 2034 2081 2128 2175 2222 2269 2316 2363 2410 2457 2504 2551 2598\n",
      " 2645 2692 2739 2786 2833 2880 2927 2974 3021 3068 3115 3162 3209 3256\n",
      " 3303 3350 3397 3444 3491 3538 3585 3632 3679 3726 3773 3820 3867 3914\n",
      " 3961 4008 4055 4102 4149 4196 4243 4290 4337 4384 4431 4478 4525 4572\n",
      " 4619 4666 4713 4760 4807 4854 4901 4948 4995 5042 5089 5136 5183 5230\n",
      " 5277 5324 5371 5418 5465 5512 5559 5606 5653 5700 5747 5794 5841 5888\n",
      " 5935 5982 6016 6017 6018 6019 6020 6022 6023 6024 6025 6026 6027 6028\n",
      " 6029 6030 6031 6032 6033 6034 6035 6036 6037 6038 6039 6040 6041 6042\n",
      " 6043 6044 6045 6046 6047 6048 6049 6050 6052 6053 6054 6055 6056 6057\n",
      " 6058 6059 6060 6061 6062 6069 6076 6085 6101 6116 6123 6132 6148 6163\n",
      " 6170 6179]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_9856\\924106973.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  X_scaled = (X - mean) / std         # Standardizasyon formulu\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Processing: sub-mit082_task-Emotion_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_9856\\700143633.py:14: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "pns: ['ECG', 'EMG', 'EMG_2']\n",
      "  raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "165 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 165 events and 501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_9856\\700143633.py:14: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_9856\\700143633.py:14: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_9856\\4259630819.py:15: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozellik cikarimi icin toplam 165 epoch işlendi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EgeTERZI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: [  13   60  107  154  201  248  295  342  389  436  483  530  577  624\n",
      "  671  718  765  812  859  906  953 1000 1047 1094 1141 1188 1235 1282\n",
      " 1329 1376 1423 1470 1517 1564 1611 1658 1705 1752 1799 1846 1893 1940\n",
      " 1987 2034 2081 2128 2175 2222 2269 2316 2363 2410 2457 2504 2551 2598\n",
      " 2645 2692 2739 2786 2833 2880 2927 2974 3021 3068 3115 3162 3209 3256\n",
      " 3303 3350 3397 3444 3491 3538 3585 3632 3679 3726 3773 3820 3867 3914\n",
      " 3961 4008 4055 4102 4149 4196 4243 4290 4337 4384 4431 4478 4525 4572\n",
      " 4619 4666 4713 4760 4807 4854 4901 4948 4995 5042 5089 5136 5183 5230\n",
      " 5277 5324 5371 5418 5465 5512 5559 5606 5653 5700 5747 5794 5841 5888\n",
      " 5935 5982 6016 6017 6018 6019 6020 6022 6023 6024 6025 6026 6027 6028\n",
      " 6029 6030 6031 6032 6033 6034 6035 6036 6037 6038 6039 6040 6041 6042\n",
      " 6043 6044 6045 6046 6047 6048 6049 6050 6052 6053 6054 6055 6056 6057\n",
      " 6058 6059 6060 6061 6062 6069 6076 6085 6101 6116 6123 6132 6148 6163\n",
      " 6170 6179]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_9856\\924106973.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  X_scaled = (X - mean) / std         # Standardizasyon formulu\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "LabelEncoder sınıfları: [ 0  1  3  8 10 11 12 13 14 15 16 17 18]\n",
      "LabelEncoder sınıf sayısı: 13\n",
      "Model tahmin unique değerleri (rf): ['IEND' 'base' 'bend' 'clic' 'fixL' 'fixl' 'qdon' 'quiz' 'rsrt' 'stm'\n",
      " 'trno' 'vlnc']\n",
      "Model tahmin unique değerleri (xgb): ['IBEG' 'IEND' 'base' 'bend' 'clic' 'fixL' 'fixl' 'qdon' 'quiz' 'rsrt'\n",
      " 'stm' 'trno' 'vlnc']\n",
      "True label unique değerleri: ['IBEG' 'IEND' 'arousal' 'base' 'bend' 'boundary' 'cate' 'clic'\n",
      " 'dominance' 'familiarity' 'fixl' 'liking' 'puse' 'qdon' 'quiz'\n",
      " 'relevance' 'rsrt' 'stm' 'stop' 'trno' 'vlnc']\n",
      "Random Forest Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        IBEG       0.00      0.00      0.00         4\n",
      "        IEND       0.00      0.00      0.00         4\n",
      "     arousal       0.00      0.00      0.00        22\n",
      "        base       0.04      0.50      0.07         2\n",
      "        bend       0.00      0.00      0.00         2\n",
      "    boundary       0.00      0.00      0.00         2\n",
      "        cate       0.00      0.00      0.00        16\n",
      "        clic       0.00      0.00      0.00        64\n",
      "   dominance       0.00      0.00      0.00        22\n",
      " familiarity       0.00      0.00      0.00        22\n",
      "        fixL       0.00      0.00      0.00         0\n",
      "        fixl       0.09      0.23      0.13        22\n",
      "      liking       0.00      0.00      0.00        22\n",
      "        puse       0.00      0.00      0.00         2\n",
      "        qdon       0.03      1.00      0.06         1\n",
      "        quiz       0.00      0.00      0.00         1\n",
      "   relevance       0.00      0.00      0.00        22\n",
      "        rsrt       0.00      0.00      0.00         2\n",
      "         stm       0.04      0.05      0.04        22\n",
      "        stop       0.00      0.00      0.00         2\n",
      "        trno       0.09      0.23      0.13        22\n",
      "        vlnc       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.04       300\n",
      "   macro avg       0.01      0.09      0.02       300\n",
      "weighted avg       0.02      0.04      0.02       300\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  1  0  1  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  2  0  0  0  0  0  1  6  0  0  3  3  0  0  2  0  2  1]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  1  0  0  0  0  0  0  3  0  0  2  0  0  0  2  0  6  0]\n",
      " [ 0  0  0  6 11  0  0  0  0  0  5 11  0  0  4  3  0  4  9  0 10  1]\n",
      " [ 0  0  0  1  5  0  0  0  0  0  0  7  0  0  1  1  0  1  1  0  4  1]\n",
      " [ 0  0  0  0  6  0  0  0  0  0  1  4  0  0  5  1  0  1  2  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  3  0  0  0  0  0  0  5  0  0  3  3  0  1  1  0  5  0]\n",
      " [ 0  1  0  1  4  0  0  0  0  0  1  4  0  0  0  5  0  0  2  0  4  0]\n",
      " [ 0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  3  3  0  0  0  0  0  2  2  0  0  4  0  0  3  4  0  1  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  1  4  0  0  1  0  0  1  2  0  0  4  3  0  1  1  0  4  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  4  0  0  2  0  0  1  4  0  0  1  0  0  0  1  0  5  1]\n",
      " [ 0  0  0  1  3  0  0  1  0  0  0  6  0  0  1  1  0  0  1  0  8  0]]\n",
      "XGBoost Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        IBEG       0.00      0.00      0.00         4\n",
      "        IEND       0.00      0.00      0.00         4\n",
      "     arousal       0.00      0.00      0.00        22\n",
      "        base       0.03      0.50      0.06         2\n",
      "        bend       0.00      0.00      0.00         2\n",
      "    boundary       0.00      0.00      0.00         2\n",
      "        cate       0.00      0.00      0.00        16\n",
      "        clic       0.25      0.09      0.14        64\n",
      "   dominance       0.00      0.00      0.00        22\n",
      " familiarity       0.00      0.00      0.00        22\n",
      "        fixL       0.00      0.00      0.00         0\n",
      "        fixl       0.12      0.14      0.13        22\n",
      "      liking       0.00      0.00      0.00        22\n",
      "        puse       0.00      0.00      0.00         2\n",
      "        qdon       0.00      0.00      0.00         1\n",
      "        quiz       0.00      0.00      0.00         1\n",
      "   relevance       0.00      0.00      0.00        22\n",
      "        rsrt       0.00      0.00      0.00         2\n",
      "         stm       0.06      0.14      0.08        22\n",
      "        stop       0.00      0.00      0.00         2\n",
      "        trno       0.07      0.18      0.10        22\n",
      "        vlnc       0.07      0.14      0.09        22\n",
      "\n",
      "    accuracy                           0.07       300\n",
      "   macro avg       0.03      0.05      0.03       300\n",
      "weighted avg       0.08      0.07      0.06       300\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  1]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  1]\n",
      " [ 0  1  0  4  0  0  0  2  0  0  1  2  0  0  0  1  0  0  4  0  4  3]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  1  0  0  0  1  2  0  0  2  0  3  5]\n",
      " [ 1  1  0  8  2  0  0  6  0  0  4  8  0  0  0  2  0  0 16  0  8  8]\n",
      " [ 0  2  0  1  1  0  0  4  0  0  0  1  0  0  0  0  0  0  3  0  7  3]\n",
      " [ 0  2  0  2  3  0  0  1  0  0  1  1  0  0  0  0  0  0  2  0  5  5]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  3  2  0  0  2  0  0  0  3  0  0  0  2  0  1  2  0  3  3]\n",
      " [ 1  0  0  2  1  0  0  0  0  0  1  0  0  0  0  1  0  0  1  0  9  6]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  1  0  0  0  0  0  3  2  0  0  1  3  0  0  6  0  3  2]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  2  0  0  3  0  0  0  3  0  0  1  2  0  0  3  0  4  3]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  5  1  0  0  2  0  0  0  0  0  0  2  3  0  0  5  0  4  0]\n",
      " [ 0  0  0  3  0  0  0  1  0  0  1  3  0  0  3  2  0  0  1  0  5  3]]\n",
      "MLP Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        IBEG       0.00      0.00      0.00         4\n",
      "        IEND       0.00      0.00      0.00         4\n",
      "     arousal       0.00      0.00      0.00        22\n",
      "        base       0.00      0.00      0.00         2\n",
      "        bend       0.00      0.00      0.00         2\n",
      "    boundary       0.00      0.00      0.00         2\n",
      "        cate       0.00      0.00      0.00        16\n",
      "        clic       0.00      0.00      0.00        64\n",
      "   dominance       0.00      0.00      0.00        22\n",
      " familiarity       0.00      0.00      0.00        22\n",
      "        fixL       0.00      0.00      0.00         0\n",
      "        fixl       0.00      0.00      0.00        22\n",
      "      liking       0.00      0.00      0.00        22\n",
      "        puse       0.00      0.00      0.00         2\n",
      "        qdon       0.00      0.00      0.00         1\n",
      "        quiz       0.00      1.00      0.01         1\n",
      "   relevance       0.00      0.00      0.00        22\n",
      "        rsrt       0.00      0.00      0.00         2\n",
      "         stm       0.00      0.00      0.00        22\n",
      "        stop       0.00      0.00      0.00         2\n",
      "        trno       0.00      0.00      0.00        22\n",
      "        vlnc       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.00       300\n",
      "   macro avg       0.00      0.05      0.00       300\n",
      "weighted avg       0.00      0.00      0.00       300\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 64  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0]]\n",
      "MODEL PERFORMANS KARŞILAŞTIRMASI:\n",
      "RF:   Accuracy=0.0433, F1=0.0197, Kappa=0.0024\n",
      "XGB:  Accuracy=0.0667, F1=0.0272, Kappa=0.0052\n",
      "MLP:  Accuracy=0.0033, F1=0.0003, Kappa=0.0000\n"
     ]
    }
   ],
   "source": [
    "def test_emotion_models(data_dir):\n",
    "    import joblib\n",
    "    \n",
    "    le = joblib.load('label_encoder.joblib')                                    # Kaydettigimiz labelleri yukluyorum\n",
    "    \n",
    "    eeg_files = glob.glob(os.path.join(data_dir, \"*.set\"))                      # Dosyadaki EEG dosya ikililerini aliyorum.\n",
    "    all_true, all_rf, all_xgb, all_mlp = [], [], [], []                         # Tum modeller icin toplu sonuclari tutuyorum.\n",
    "    for eeg_file in eeg_files:\n",
    "        event_file = eeg_file.replace('_eeg.set', '_events.tsv')\n",
    "        if not os.path.exists(event_file):\n",
    "            print(f\"Event file not found: {event_file}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processing: {os.path.basename(eeg_file)}\")\n",
    "        results = predict_emotions(eeg_file, event_file)\n",
    "        \n",
    "        if not results:\n",
    "            continue\n",
    "            \n",
    "        all_true.extend(results['true'])\n",
    "        all_rf.extend(results['rf'])\n",
    "        all_xgb.extend(results['xgb'])\n",
    "        all_mlp.extend(results['mlp'])\n",
    "\n",
    "    if len(all_true) == 0:\n",
    "        print(\"Data işlenemedi.\")\n",
    "        return\n",
    "    \n",
    "    classes = le.classes_\n",
    "\n",
    "    print(\"LabelEncoder sınıfları:\", classes)\n",
    "    print(\"LabelEncoder sınıf sayısı:\", len(classes))\n",
    "    print(\"Model tahmin unique değerleri (rf):\", np.unique(all_rf))\n",
    "    print(\"Model tahmin unique değerleri (xgb):\", np.unique(all_xgb))\n",
    "    print(\"True label unique değerleri:\", np.unique(all_true))\n",
    "    all_unique_labels = sorted(list(set(all_true) | set(all_rf) | set(all_xgb) | set(all_mlp)))                     # Tum essiz labellari aliyorum.\n",
    "    \n",
    "\n",
    "    print(\"Random Forest Performance:\")                                                                                             # Modellerin performanslarini hesapliyoruz.\n",
    "    print(classification_report(all_true, all_rf, labels=all_unique_labels, target_names=all_unique_labels, zero_division=0))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_rf, labels=all_unique_labels))\n",
    "    \n",
    "    print(\"XGBoost Performance:\")\n",
    "    print(classification_report(all_true, all_xgb, labels=all_unique_labels, target_names=all_unique_labels, zero_division=0))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_xgb, labels=all_unique_labels))\n",
    "    \n",
    "    print(\"MLP Performance:\")\n",
    "    print(classification_report(all_true, all_mlp, labels=all_unique_labels, target_names=all_unique_labels, zero_division=0))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_mlp, labels=all_unique_labels))\n",
    "    \n",
    "\n",
    "    rf_metrics = calculate_metrics(all_true, all_rf)                                                                               # Kullandigimiz modellerin metriklerini hesapliyoruz.\n",
    "    xgb_metrics = calculate_metrics(all_true, all_xgb)\n",
    "    mlp_metrics = calculate_metrics(all_true, all_mlp)\n",
    "    \n",
    "    print(\"MODEL PERFORMANS KARŞILAŞTIRMASI:\")\n",
    "    print(f\"RF:   Accuracy={rf_metrics[0]:.4f}, F1={rf_metrics[1]:.4f}, Kappa={rf_metrics[2]:.4f}\")\n",
    "    print(f\"XGB:  Accuracy={xgb_metrics[0]:.4f}, F1={xgb_metrics[1]:.4f}, Kappa={xgb_metrics[2]:.4f}\")\n",
    "    print(f\"MLP:  Accuracy={mlp_metrics[0]:.4f}, F1={mlp_metrics[1]:.4f}, Kappa={mlp_metrics[2]:.4f}\")\n",
    "\n",
    "label_mapping = {\n",
    "    'ibeg': 0, 'iend': 1, 'rsrt': 2, 'fixl': 3,\n",
    "    'quiz': 4, 'qdon': 5, 'base': 6, 'bend': 7, 'trno': 8,\n",
    "    'fixL': 9, 'stm': 10, 'clic': 11, 'vlnc': 12, 'arsl': 13,\n",
    "    'dmns': 14, 'lkng': 15, 'fmrt': 16, 'relv': 17, 'cate': 18,\n",
    "    'IBEG': 0, 'IEND': 1, 'puse': 19, 'boundary': 20, 'stop': 21,\n",
    "    'baseline': 22, 'baseend': 23, 'trialno': 24, 'fixation loop': 25,\n",
    "    'neutral_1_1': 26, 'valence': 27, 'arousal': 13, 'dominance': 14, 'liking': 15,\n",
    "    'familiarity': 16, 'relevance': 17, '3_2': 28, 'click': 29,\n",
    "    'impedances begin': 30, 'emotion_categ': 31, 'impedances end': 32, 'stop event': 33\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_data_dir = \"./EmotionData/Emotion_EDF_Testing_Data\"\n",
    "    test_emotion_models(test_data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
