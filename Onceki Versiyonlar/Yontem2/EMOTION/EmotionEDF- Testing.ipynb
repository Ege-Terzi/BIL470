{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4338abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from scipy import stats\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, cohen_kappa_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6834122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks, welch\n",
    "from scipy.stats import entropy, kurtosis, skew, iqr\n",
    "\n",
    "def bandpower(psd, freqs, fmin, fmax):\n",
    "    idx_band = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
    "    return np.sum(psd[idx_band])\n",
    "\n",
    "def extract_emotion_features(data, sfreq, n_fft_comp=5):\n",
    "    feature_list = []\n",
    "    count = 0\n",
    "    \n",
    "    # Zaman serisinde ozellik cikarimi yapiyorum. Buradaki ozniteliklerin cogunu TSFEL: Time Series Feature Extraction Library makalesinden aldim.\n",
    "\n",
    "    for epoch in data:\n",
    "        feats = []\n",
    "        for ch_signal in epoch:\n",
    "            t = np.arange(len(ch_signal))\n",
    "            abs_energy = np.sum(ch_signal**2)                                                           # Sinyalin toplam enerjisi, guc olcusu\n",
    "            area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n",
    "            \n",
    "            autocorr = np.corrcoef(ch_signal[:-1], ch_signal[1:])[0, 1] if np.std(ch_signal) > 0 else 0 # Sinyalin kendisiyle bir gecikmeyle olan korelasyonu\n",
    "            \n",
    "            avg_power = np.mean(ch_signal**2)                                                           # Ortalama guc\n",
    "            centroid = np.sum(t * np.abs(ch_signal)) / (np.sum(np.abs(ch_signal)) + 1e-12)              # Sinyal agirlik merkezi\n",
    "            \n",
    "            hist, _ = np.histogram(ch_signal, bins=10, density=True)\n",
    "            hist_entropy = entropy(hist + 1e-12)                                                        # Sinyal genlik dagiliminin duzensizligi\n",
    "            \n",
    "            freqs, psd = welch(ch_signal, sfreq, nperseg=min(256, len(ch_signal)))\n",
    "            psd /= np.sum(psd) + 1e-12                                                                  # Frekanslara gore enerji dagilimi\n",
    "            \n",
    "            fund_freq = freqs[np.argmax(psd)] if len(psd) > 0 else 0                                    # En yuksek guce sahip frekans bileşeni\n",
    "            \n",
    "            hist_vals, hist_bins = np.histogram(ch_signal, bins=10)\n",
    "            hist_mode = hist_bins[np.argmax(hist_vals)]                                                 # En cok gorulen genlik degeri\n",
    "            \n",
    "            human_energy = np.sum(psd[(freqs >= 0.5) & (freqs <= 40)])                                  # Insan EEG bandindaki enerji\n",
    "            iqr_val = iqr(ch_signal)                                                                    # Sinyalin orta %50'sinin yayilimi\n",
    "            kurt_val = kurtosis(ch_signal)                                                              # Carpiklik, uc deger yogunlugu\n",
    "            \n",
    "            max_val = np.max(ch_signal)                                                                 # Maksimum deger\n",
    "            max_psd = np.max(psd)                                                                       # Maksimum guc\n",
    "            max_freq = freqs[-1]                                                                        # En yuksek olculebilir frekans\n",
    "            \n",
    "            mean_val = np.mean(ch_signal)                                                               # Ortalama deger\n",
    "            mad = np.mean(np.abs(ch_signal - mean_val))                                                 # Ortalama mutlak sapma\n",
    "            mean_abs_diff = np.mean(np.abs(np.diff(ch_signal)))                                         # Komşu ornekler arasindaki ortalama mutlak fark\n",
    "            mean_diff = np.mean(np.diff(ch_signal))                                                     # Komşu ornekler arasindaki ortalama fark\n",
    "            \n",
    "            med_val = np.median(ch_signal)                                                              # Medyan deger\n",
    "            med_abs_dev = np.median(np.abs(ch_signal - med_val))                                        # Medyan mutlak sapma\n",
    "            med_abs_diff = np.median(np.abs(np.diff(ch_signal)))                                        # Medyan komşu mutlak farki\n",
    "            med_diff = np.median(np.diff(ch_signal))                                                    # Medyan komşu farki\n",
    "            cumulative_power = np.cumsum(psd)\n",
    "            med_freq = freqs[np.argmax(cumulative_power >= 0.5)] if len(psd) > 0 else 0                 # Medyan frekans\n",
    "            \n",
    "            min_val = np.min(ch_signal)                                                                 # Minimum deger\n",
    "            \n",
    "            diff_signal = np.diff(ch_signal)\n",
    "            sign_changes = np.diff(np.sign(diff_signal))\n",
    "            neg_turning = np.sum(sign_changes > 0)                                                      # Negatif egimden pozitif egime geciş sayisi\n",
    "            pos_turning = np.sum(sign_changes < 0)                                                      # Pozitif egimden negatif egime geciş sayisi\n",
    "            peaks, _ = find_peaks(ch_signal)\n",
    "            n_peaks = len(peaks)                                                                        # Tepe sayisi\n",
    "            peak_dist = np.mean(np.diff(peaks)) if n_peaks > 1 else 0                                   # Tepeler arasi ortalama mesafe\n",
    "            \n",
    "            if len(psd) > 0:\n",
    "                peak_psd = np.max(psd)\n",
    "                mask = psd >= (peak_psd / 2)\n",
    "                try:\n",
    "                    power_bandwidth = freqs[mask][-1] - freqs[mask][0]                                  # Gucun %50'sinden fazlasini iceren frekans araligi\n",
    "                except:\n",
    "                    power_bandwidth = 0\n",
    "            else:\n",
    "                power_bandwidth = 0\n",
    "                \n",
    "            rms = np.sqrt(avg_power)                                                                    \n",
    "            signal_dist = np.sum(np.abs(ch_signal))                                                     # Mutlak genlik toplami\n",
    "            skew_val = skew(ch_signal)                                                                  # Simetri olcusu\n",
    "            slope = np.polyfit(t, ch_signal, 1)[0]                                                      # Lineer egim, trend\n",
    "            \n",
    "            spec_centroid = np.sum(freqs * psd) / (np.sum(psd) + 1e-12)                                 # Spektral agirlik merkezi\n",
    "            spec_decrease = np.sum((psd[1:] - psd[0]) / np.arange(1, len(psd))) / (np.sum(psd[1:]) + 1e-12) if len(psd) > 1 else 0   # Yuksek frekanslardaki guc kaybi\n",
    "            spec_ent = entropy(psd + 1e-12)                                                             # Spektral entropi\n",
    "            spec_kurt = kurtosis(psd)                                                                   # Spektral carpiklik\n",
    "            diff_psd = np.diff(psd)\n",
    "            psd_sign_changes = np.diff(np.sign(diff_psd))\n",
    "            spec_pos_turning = np.sum(psd_sign_changes < 0)                                             # Spektral donuş noktasi sayisi\n",
    "            spec_roll_off = freqs[np.argmax(cumulative_power >= 0.85)] if len(psd) > 0 else 0           # Enerjinin %85'ine ulaşilan frekans\n",
    "            spec_roll_on = freqs[np.argmax(cumulative_power >= 0.05)] if len(psd) > 0 else 0            # Enerjinin %5'ine ulaşilan frekans\n",
    "            spec_skew = skew(psd)                                                                       # Spektral skewness\n",
    "            spec_slope = np.polyfit(freqs, psd, 1)[0] if len(psd) > 1 else 0                            # Spektral egim\n",
    "            spec_spread = np.sqrt(np.sum(psd * (freqs - spec_centroid)**2) / (np.sum(psd) + 1e-12))     # Spektral yayilma\n",
    "            \n",
    "            std = np.std(ch_signal)                                                                     # Standart sapma\n",
    "            sum_abs_diff = np.sum(np.abs(np.diff(ch_signal)))                                           # Ornekler arasi toplam fark\n",
    "            var = np.var(ch_signal)                                                                     # Varyans\n",
    "            \n",
    "            zero_crossings = np.sum(np.diff(np.sign(ch_signal)) != 0)\n",
    "            zcr = zero_crossings / len(ch_signal)                                                       # Sinyalin kac kez sifiri gectigi\n",
    "\n",
    "            bp_delta = bandpower(psd, freqs, 0.5, 4)                                                    # Bant güçleri (delta: 0.5–4Hz, theta: 4–8Hz, alpha: 8–13Hz, beta: 13–30Hz, gamma: 30–40Hz)\n",
    "            bp_theta = bandpower(psd, freqs, 4, 8)\n",
    "            bp_alpha = bandpower(psd, freqs, 8, 13)\n",
    "            bp_beta  = bandpower(psd, freqs, 13, 30)\n",
    "            bp_gamma = bandpower(psd, freqs, 30, 40)\n",
    "            \n",
    "            fft_vals = np.fft.rfft(ch_signal)                                                           # FFT bileşenleri (en büyük n_fft_comp genlik)\n",
    "            fft_power = np.abs(fft_vals)\n",
    "            top_fft_indices = np.argsort(fft_power)[-n_fft_comp:][::-1]\n",
    "            top_fft_components = fft_power[top_fft_indices]\n",
    "\n",
    "            features = [\n",
    "                abs_energy, area_curve, autocorr, avg_power, centroid, hist_entropy,\n",
    "                fund_freq, hist_mode, human_energy, iqr_val, kurt_val, max_val,\n",
    "                bp_delta, bp_theta, bp_alpha, bp_beta, bp_gamma, *top_fft_components,\n",
    "                max_psd, max_freq, mean_val, mad, mean_abs_diff, mean_diff, med_val,\n",
    "                med_abs_dev, med_abs_diff, med_diff, med_freq, min_val, neg_turning,\n",
    "                n_peaks, peak_dist, pos_turning, power_bandwidth, rms, signal_dist,\n",
    "                skew_val, slope, spec_centroid, spec_decrease, spec_ent,\n",
    "                spec_kurt, spec_pos_turning, spec_roll_off, spec_roll_on, spec_skew,\n",
    "                spec_slope, spec_spread, std, sum_abs_diff, var, zcr\n",
    "            ]\n",
    "            \n",
    "            feats.extend(features)\n",
    "            \n",
    "        feature_list.append(feats)\n",
    "        count += 1\n",
    "        \n",
    "    print(f\"Özellik çıkarımı için toplam {count} epoch işlendi.\")\n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511650b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'ibeg': 0, 'iend': 1, 'rsrt': 2, 'fixl': 3,\n",
    "    'quiz': 4, 'qdon': 5, 'base': 6, 'bend': 7, 'trno': 8,\n",
    "    'fixL': 9, 'stm': 10, 'clic': 11, 'vlnc': 12, 'arsl': 13,\n",
    "    'dmns': 14, 'lkng': 15, 'fmrt': 16, 'relv': 17, 'cate': 18,\n",
    "    'IBEG': 0, 'IEND': 1, 'puse': 19, 'boundary': 20, 'stop': 21,\n",
    "    'baseline': 22,'baseend': 23,'trialno': 24,'fixation loop': 25,\n",
    "    'neutral_1_1': 26,'valence': 27,'arousal': 13,'dominance': 14,'liking': 15,\n",
    "    'familiarity': 16,'relevance': 17,'3_2': 28,'click': 29,\n",
    "    'impedances begin': 30,'emotion_categ': 31,'impedances end': 32,'stop event': 33\n",
    "}\n",
    "\n",
    "def create_sequences(data, seq_length=10):                                                              # Zaman serisi verileri olusturuyorum.\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length + 1):\n",
    "        sequences.append(data[i:i+seq_length])\n",
    "    return np.array(sequences)\n",
    "\n",
    "\n",
    "def preprocess_emotion_data(eeg_file, event_file, epoch_duration=2.0):\n",
    "    try:\n",
    "        raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n",
    "        events_df = pd.read_csv(event_file, sep='\\t')\n",
    "        \n",
    "        events = []\n",
    "        for _, row in events_df.iterrows():                                                             # Etiketleri sayisallastiriyorum\n",
    "            sample = int(row['onset'] * raw.info['sfreq']/1000)\n",
    "            label_str = str(row['trial_type']).lower().strip()\n",
    "            label = label_mapping.get(label_str, -1)\n",
    "            if label >= 0:\n",
    "                events.append([sample, 0, label])\n",
    "        \n",
    "        events_array = np.array(events, dtype=np.int64)\n",
    "        \n",
    "        epochs = mne.Epochs(                                                                            # Epochlari olusturuyorum.\n",
    "            raw,\n",
    "            events_array,\n",
    "            tmin=0.0,\n",
    "            tmax=epoch_duration,\n",
    "            baseline=None,\n",
    "            preload=True,\n",
    "            reject_by_annotation=False\n",
    "        )\n",
    "        \n",
    "        data = epochs.get_data()                                                                        # Epoch verilerinin ozelliklerini cikartiyorum.\n",
    "        features = extract_emotion_features(data, raw.info['sfreq'])    \n",
    "        labels = epochs.events[:, -1]\n",
    "        \n",
    "        return features, labels\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {eeg_file}: {str(e)}\")\n",
    "        return np.array([]), np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecba96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "def predict_emotions(eeg_file, event_file, seq_length=10):\n",
    "\n",
    "    features, true_labels = preprocess_emotion_data(eeg_file, event_file)                                   # Ham ozellikleri ve gercek etiketleri cikartiyorm.\n",
    "    if features.size == 0:\n",
    "        return {}\n",
    "\n",
    "    imputer = joblib.load('imputer.joblib')                                                                 # Kaydedilmis preprocessing objelerini yukluyorum\n",
    "    selected_indices = joblib.load('selected_feature_indices.joblib')\n",
    "    scaler = joblib.load('scaler.joblib')\n",
    "\n",
    "    n_imp = imputer.n_features_in_                                                                          # Ozellik boyutunu imputerin bekledigi formata getiriyorum.\n",
    "    if features.shape[1] != n_imp:\n",
    "        print(f\"Özellik sayısı uyumsuz: beklenen {n_imp}, gelen {features.shape[1]}. Kırpılıyor.\")\n",
    "        features = features[:, :n_imp]\n",
    "\n",
    "\n",
    "    features_imp = imputer.transform(features)                                                              # Impute ediyorum ve sadece secilmis indeksleri aliyorum.\n",
    "    features_sel = features_imp[:, selected_indices]\n",
    "\n",
    "    n_scl = scaler.n_features_in_                                                                           # Scalerin bekledigi boyuta getiriyorum.\n",
    "    if features_sel.shape[1] != n_scl:\n",
    "        print(f\"Scalerın bekldigi {n_scl} öznitelik, ama elimde {features_sel.shape[1]} var. Kırpılıyor.\")\n",
    "        features_sel = features_sel[:, :n_scl]\n",
    "\n",
    "    features_scaled = scaler.transform(features_sel)                                                        # Olceklendirme yapiyorum.\n",
    "\n",
    "    if len(features_scaled) < seq_length:                                                                   # Zaman serisi dizilerini olusturuyorum\n",
    "        print(f\"Yeterli epoch yok ({len(features_scaled)}) — seq_length={seq_length}\")\n",
    "        return {}\n",
    "    sequences = create_sequences(features_scaled, seq_length)\n",
    "\n",
    "    rnn_model = load_model('rnn_model.h5')                                                                  # Modelleri yukluyorum ve tahmin yapiyorum.\n",
    "    lstm_model = load_model('lstm_model.h5')\n",
    "    gru_model = load_model('gru_model.h5')\n",
    "    transformer_model = load_model('transformer_model.keras')\n",
    "\n",
    "    rnn_preds = np.argmax(rnn_model.predict(sequences, verbose=0), axis=1)\n",
    "    lstm_preds = np.argmax(lstm_model.predict(sequences, verbose=0), axis=1)\n",
    "    gru_preds = np.argmax(gru_model.predict(sequences, verbose=0), axis=1)\n",
    "    transformer_preds = np.argmax(transformer_model.predict(sequences, verbose=0), axis=1)\n",
    "\n",
    "    true_labels_seq = true_labels[seq_length - 1:]\n",
    "\n",
    "    mapping_inverse = {v: k for k, v in label_mapping.items()}                                  \n",
    "    results = {\n",
    "        'true':        [mapping_inverse.get(x, 'UNKNOWN') for x in true_labels_seq],\n",
    "        'rnn':        [mapping_inverse.get(x, 'UNKNOWN') for x in rnn_preds],\n",
    "        'lstm':        [mapping_inverse.get(x, 'UNKNOWN') for x in lstm_preds],\n",
    "        'gru':         [mapping_inverse.get(x, 'UNKNOWN') for x in gru_preds],\n",
    "        'transformer': [mapping_inverse.get(x, 'UNKNOWN') for x in transformer_preds]\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebaa9e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):                                          # Performans verilerini elde ediyorum.\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    return acc, f1, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6787f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: sub-mit081_task-Emotion_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_16352\\4213367931.py:22: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "pns: ['ECG', 'EMG', 'EMG_2']\n",
      "  raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "135 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 135 events and 501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_16352\\4213367931.py:22: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_16352\\2194839627.py:19: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Özellik çıkarımı için toplam 135 epoch işlendi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C26BDAB130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C26BDAB130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C26BDAB130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C26BDAB130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: sub-mit082_task-Emotion_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_16352\\4213367931.py:22: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "pns: ['ECG', 'EMG', 'EMG_2']\n",
      "  raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "165 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 165 events and 501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_16352\\4213367931.py:22: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_16352\\4213367931.py:22: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)                             # EEG verisini ve olaylari yukluyoruz.\n",
      "C:\\Users\\EgeTERZI\\AppData\\Local\\Temp\\ipykernel_16352\\2194839627.py:19: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  area_curve = np.trapz(ch_signal)                                                            # Egri alti alan, sinyalin integraline benzer toplam degeri\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Özellik çıkarımı için toplam 165 epoch işlendi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder sınıfları: [ 3  8 10 11 12 13 14 15 16 17]\n",
      "LabelEncoder sınıf sayısı: 10\n",
      "Model tahmin unique değerleri (RNN): ['dominance' 'familiarity' 'fixl' 'liking' 'trno' 'vlnc']\n",
      "Model tahmin unique değerleri (LSTM): ['IBEG' 'IEND' 'bend' 'fixl']\n",
      "Model tahmin unique değerleri (GRU): ['IBEG' 'base' 'baseline' 'dominance' 'fixL' 'quiz' 'vlnc']\n",
      "Model tahmin unique değerleri (Transformer): ['IBEG' 'arousal' 'base' 'fixL' 'quiz' 'trno']\n",
      "True label unique değerleri: ['IBEG' 'IEND' 'arousal' 'boundary' 'cate' 'clic' 'dominance'\n",
      " 'familiarity' 'fixl' 'liking' 'puse' 'relevance' 'rsrt' 'stm' 'stop'\n",
      " 'trno' 'vlnc']\n",
      "RNN Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        IBEG       0.00      0.00      0.00         4\n",
      "        IEND       0.00      0.00      0.00         4\n",
      "     arousal       0.00      0.00      0.00        21\n",
      "        base       0.00      0.00      0.00         0\n",
      "    baseline       0.00      0.00      0.00         0\n",
      "        bend       0.00      0.00      0.00         0\n",
      "    boundary       0.00      0.00      0.00         2\n",
      "        cate       0.00      0.00      0.00        16\n",
      "        clic       0.00      0.00      0.00        63\n",
      "   dominance       0.06      0.10      0.08        21\n",
      " familiarity       0.10      0.27      0.15        22\n",
      "        fixL       0.00      0.00      0.00         0\n",
      "        fixl       0.06      0.05      0.05        20\n",
      "      liking       0.07      0.24      0.11        21\n",
      "        puse       0.00      0.00      0.00         2\n",
      "        quiz       0.00      0.00      0.00         0\n",
      "   relevance       0.00      0.00      0.00        22\n",
      "        rsrt       0.00      0.00      0.00         2\n",
      "         stm       0.00      0.00      0.00        20\n",
      "        stop       0.00      0.00      0.00         2\n",
      "        trno       0.08      0.35      0.12        20\n",
      "        vlnc       0.08      0.05      0.06        20\n",
      "\n",
      "    accuracy                           0.08       282\n",
      "   macro avg       0.02      0.05      0.03       282\n",
      "weighted avg       0.03      0.08      0.04       282\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  4  0  1  6  0  0  0  0  0  0  6  3]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  4  0  1  1  0  0  0  0  0  0  6  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  9 10  0  5 14  0  0  0  0  0  0 24  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  5  0  1  6  0  0  0  0  0  0  7  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  6  0  1  5  0  0  0  0  0  0  8  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  5  0  1  5  0  0  0  0  0  0  5  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  5  0  1  5  0  0  0  0  0  0  7  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  3  0  1  8  0  0  0  0  0  0  6  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  5  0  2  5  0  0  0  0  0  0  5  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  5  0  0  5  0  0  0  0  0  0  7  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  3  0  2  8  0  0  0  0  0  0  4  1]]\n",
      "LSTM Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        IBEG       0.02      0.25      0.04         4\n",
      "        IEND       0.01      0.75      0.03         4\n",
      "     arousal       0.00      0.00      0.00        21\n",
      "        base       0.00      0.00      0.00         0\n",
      "    baseline       0.00      0.00      0.00         0\n",
      "        bend       0.00      0.00      0.00         0\n",
      "    boundary       0.00      0.00      0.00         2\n",
      "        cate       0.00      0.00      0.00        16\n",
      "        clic       0.00      0.00      0.00        63\n",
      "   dominance       0.00      0.00      0.00        21\n",
      " familiarity       0.00      0.00      0.00        22\n",
      "        fixL       0.00      0.00      0.00         0\n",
      "        fixl       0.00      0.00      0.00        20\n",
      "      liking       0.00      0.00      0.00        21\n",
      "        puse       0.00      0.00      0.00         2\n",
      "        quiz       0.00      0.00      0.00         0\n",
      "   relevance       0.00      0.00      0.00        22\n",
      "        rsrt       0.00      0.00      0.00         2\n",
      "         stm       0.00      0.00      0.00        20\n",
      "        stop       0.00      0.00      0.00         2\n",
      "        trno       0.00      0.00      0.00        20\n",
      "        vlnc       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.01       282\n",
      "   macro avg       0.00      0.05      0.00       282\n",
      "weighted avg       0.00      0.01      0.00       282\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3 12  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [13 47  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 17  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 15  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 15  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "GRU Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        IBEG       0.03      0.50      0.05         4\n",
      "        IEND       0.00      0.00      0.00         4\n",
      "     arousal       0.00      0.00      0.00        21\n",
      "        base       0.00      0.00      0.00         0\n",
      "    baseline       0.00      0.00      0.00         0\n",
      "        bend       0.00      0.00      0.00         0\n",
      "    boundary       0.00      0.00      0.00         2\n",
      "        cate       0.00      0.00      0.00        16\n",
      "        clic       0.00      0.00      0.00        63\n",
      "   dominance       0.10      0.14      0.12        21\n",
      " familiarity       0.00      0.00      0.00        22\n",
      "        fixL       0.00      0.00      0.00         0\n",
      "        fixl       0.00      0.00      0.00        20\n",
      "      liking       0.00      0.00      0.00        21\n",
      "        puse       0.00      0.00      0.00         2\n",
      "        quiz       0.00      0.00      0.00         0\n",
      "   relevance       0.00      0.00      0.00        22\n",
      "        rsrt       0.00      0.00      0.00         2\n",
      "         stm       0.00      0.00      0.00        20\n",
      "        stop       0.00      0.00      0.00         2\n",
      "        trno       0.00      0.00      0.00        20\n",
      "        vlnc       0.10      0.25      0.14        20\n",
      "\n",
      "    accuracy                           0.04       282\n",
      "   macro avg       0.01      0.04      0.01       282\n",
      "weighted avg       0.01      0.04      0.02       282\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 1  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 5  0  0  6  1  0  0  0  0  4  0  0  0  0  0  1  0  0  0  0  0  4]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  3  1  0  0  0  0  2  0  1  0  0  0  1  0  0  0  0  0  4]\n",
      " [14  0  0 20  4  0  0  0  0  7  0  0  0  0  0  3  0  0  0  0  0 15]\n",
      " [ 4  0  0  8  2  0  0  0  0  3  0  0  0  0  0  1  0  0  0  0  0  3]\n",
      " [ 3  0  0 10  2  0  0  0  0  2  0  2  0  0  0  1  0  0  0  0  0  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  5  0  0  0  0  0  2  0  1  0  0  0  2  0  0  0  0  0  3]\n",
      " [ 6  0  0  6  2  0  0  0  0  2  0  2  0  0  0  1  0  0  0  0  0  2]\n",
      " [ 1  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  0  8  1  0  0  0  0  1  0  2  0  0  0  1  0  0  0  0  0  3]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  0  8  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  4]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  0  5  1  0  0  0  0  2  0  0  0  0  0  2  0  0  0  0  0  4]\n",
      " [ 3  0  0  8  2  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  5]]\n",
      "Transformer Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        IBEG       0.00      0.00      0.00         4\n",
      "        IEND       0.00      0.00      0.00         4\n",
      "     arousal       0.07      0.43      0.11        21\n",
      "        base       0.00      0.00      0.00         0\n",
      "    baseline       0.00      0.00      0.00         0\n",
      "        bend       0.00      0.00      0.00         0\n",
      "    boundary       0.00      0.00      0.00         2\n",
      "        cate       0.00      0.00      0.00        16\n",
      "        clic       0.00      0.00      0.00        63\n",
      "   dominance       0.00      0.00      0.00        21\n",
      " familiarity       0.00      0.00      0.00        22\n",
      "        fixL       0.00      0.00      0.00         0\n",
      "        fixl       0.00      0.00      0.00        20\n",
      "      liking       0.00      0.00      0.00        21\n",
      "        puse       0.00      0.00      0.00         2\n",
      "        quiz       0.00      0.00      0.00         0\n",
      "   relevance       0.00      0.00      0.00        22\n",
      "        rsrt       0.00      0.00      0.00         2\n",
      "         stm       0.00      0.00      0.00        20\n",
      "        stop       0.00      0.00      0.00         2\n",
      "        trno       0.00      0.00      0.00        20\n",
      "        vlnc       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.03       282\n",
      "   macro avg       0.00      0.02      0.01       282\n",
      "weighted avg       0.00      0.03      0.01       282\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  9  8  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0 10  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 4  0 35 19  0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  3  0]\n",
      " [ 2  0 10  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  9 11  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  9  7  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  9 10  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0]\n",
      " [ 0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0 10  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  9  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  9  8  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  9  9  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]]\n",
      "MODEL PERFORMANS KARŞILAŞTIRMASI:\n",
      "RNN:   Accuracy=0.0780, F1=0.0338, Kappa=0.0047\n",
      "LSTM:   Accuracy=0.0142, F1=0.0035, Kappa=-0.0001\n",
      "GRU:  Accuracy=0.0355, F1=0.0148, Kappa=0.0113\n",
      "Transformer:  Accuracy=0.0355, F1=0.0148, Kappa=0.0113\n"
     ]
    }
   ],
   "source": [
    "def test_emotion_models(data_dir):\n",
    "    import joblib\n",
    "    \n",
    "    le = joblib.load('label_encoder.joblib')                                    # Kaydettigimiz labelleri yukluyorum\n",
    "    \n",
    "    eeg_files = glob.glob(os.path.join(data_dir, \"*.set\"))                      # Dosyadaki EEG dosya ikililerini aliyorum.\n",
    "    all_true, all_rnn, all_lstm, all_gru, all_transformer = [], [], [], [], []              # Tum modeller icin toplu sonuclari tutuyorum.\n",
    "    for eeg_file in eeg_files:\n",
    "        event_file = eeg_file.replace('_eeg.set', '_events.tsv')\n",
    "        if not os.path.exists(event_file):\n",
    "            print(f\"Event file not found: {event_file}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processing: {os.path.basename(eeg_file)}\")\n",
    "        results = predict_emotions(eeg_file, event_file)\n",
    "        \n",
    "        if not results:\n",
    "            continue\n",
    "            \n",
    "        all_true.extend(results['true'])\n",
    "        all_rnn.extend(results['rnn'])\n",
    "        all_lstm.extend(results['lstm'])\n",
    "        all_gru.extend(results['gru'])\n",
    "        all_transformer.extend(results['transformer'])\n",
    "\n",
    "    if len(all_true) == 0:\n",
    "        print(\"Data işlenemedi.\")\n",
    "        return\n",
    "    \n",
    "    classes = le.classes_\n",
    "\n",
    "    print(\"LabelEncoder sınıfları:\", classes)\n",
    "    print(\"LabelEncoder sınıf sayısı:\", len(classes))\n",
    "    print(\"Model tahmin unique değerleri (RNN):\", np.unique(all_rnn))\n",
    "    print(\"Model tahmin unique değerleri (LSTM):\", np.unique(all_lstm))\n",
    "    print(\"Model tahmin unique değerleri (GRU):\", np.unique(all_gru))\n",
    "    print(\"Model tahmin unique değerleri (Transformer):\", np.unique(all_transformer))\n",
    "    print(\"True label unique değerleri:\", np.unique(all_true))\n",
    "    all_unique_labels = sorted(set(all_true + all_rnn + all_lstm + all_gru + all_transformer))                     # Tum essiz labellari aliyorum.\n",
    "    \n",
    "\n",
    "    print(\"RNN Performance:\")                                                                                             # Modellerin performanslarini hesapliyoruz.\n",
    "    print(classification_report(all_true, all_rnn, labels=all_unique_labels, target_names=all_unique_labels, zero_division=0))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_rnn, labels=all_unique_labels))\n",
    "    \n",
    "    print(\"LSTM Performance:\")                                                                                            \n",
    "    print(classification_report(all_true, all_lstm, labels=all_unique_labels, target_names=all_unique_labels, zero_division=0))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_lstm, labels=all_unique_labels))\n",
    "\n",
    "    print(\"GRU Performance:\")\n",
    "    print(classification_report(all_true, all_gru, labels=all_unique_labels, target_names=all_unique_labels, zero_division=0))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_gru, labels=all_unique_labels))\n",
    "    \n",
    "    print(\"Transformer Performance:\")\n",
    "    print(classification_report(all_true, all_transformer, labels=all_unique_labels, target_names=all_unique_labels, zero_division=0))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_true, all_transformer, labels=all_unique_labels))\n",
    "    \n",
    "\n",
    "    lstm_metrics = calculate_metrics(all_true, all_lstm)                                                                               # Kullandigimiz metrikleri hesapliyoruz.\n",
    "    rnn_metrics = calculate_metrics(all_true, all_rnn)\n",
    "    gru_metrics = calculate_metrics(all_true, all_gru)\n",
    "    transformer_metrics = calculate_metrics(all_true, all_gru)\n",
    "    \n",
    "    print(\"MODEL PERFORMANS KARŞILAŞTIRMASI:\")\n",
    "    print(f\"RNN:   Accuracy={rnn_metrics[0]:.4f}, F1={rnn_metrics[1]:.4f}, Kappa={rnn_metrics[2]:.4f}\")\n",
    "    print(f\"LSTM:   Accuracy={lstm_metrics[0]:.4f}, F1={lstm_metrics[1]:.4f}, Kappa={lstm_metrics[2]:.4f}\")\n",
    "    print(f\"GRU:  Accuracy={gru_metrics[0]:.4f}, F1={gru_metrics[1]:.4f}, Kappa={gru_metrics[2]:.4f}\")\n",
    "    print(f\"Transformer:  Accuracy={transformer_metrics[0]:.4f}, F1={transformer_metrics[1]:.4f}, Kappa={transformer_metrics[2]:.4f}\")\n",
    "\n",
    "label_mapping = {\n",
    "    'ibeg': 0, 'iend': 1, 'rsrt': 2, 'fixl': 3,\n",
    "    'quiz': 4, 'qdon': 5, 'base': 6, 'bend': 7, 'trno': 8,\n",
    "    'fixL': 9, 'stm': 10, 'clic': 11, 'vlnc': 12, 'arsl': 13,\n",
    "    'dmns': 14, 'lkng': 15, 'fmrt': 16, 'relv': 17, 'cate': 18,\n",
    "    'IBEG': 0, 'IEND': 1, 'puse': 19, 'boundary': 20, 'stop': 21,\n",
    "    'baseline': 22, 'baseend': 23, 'trialno': 24, 'fixation loop': 25,\n",
    "    'neutral_1_1': 26, 'valence': 27, 'arousal': 13, 'dominance': 14, 'liking': 15,\n",
    "    'familiarity': 16, 'relevance': 17, '3_2': 28, 'click': 29,\n",
    "    'impedances begin': 30, 'emotion_categ': 31, 'impedances end': 32, 'stop event': 33\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_data_dir = \"./EmotionData/Emotion_EDF_Testing_Data\"\n",
    "    test_emotion_models(test_data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
